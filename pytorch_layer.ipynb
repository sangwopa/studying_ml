{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bbb0ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df69953c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    }
   ],
   "source": [
    "# device 정의\n",
    "if torch.cuda.is_available():    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43ef7083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망 클래스 정의\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5be1e64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# class 인스턴스 생성, device로 이동, 구조 출력\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5104be32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.9683, 0.6818, 0.6710, 0.8092, 0.4454, 0.5243, 0.9275, 0.8733,\n",
      "          0.1623, 0.7460, 0.4681, 0.5301, 0.4669, 0.6500, 0.8882, 0.2640,\n",
      "          0.9628, 0.2620, 0.7879, 0.7694, 0.4595, 0.8991, 0.7389, 0.0677,\n",
      "          0.3935, 0.2958, 0.2889, 0.5916],\n",
      "         [0.7065, 0.5291, 0.1189, 0.2766, 0.4077, 0.9533, 0.1757, 0.3494,\n",
      "          0.9980, 0.3956, 0.2855, 0.4121, 0.6640, 0.0159, 0.4375, 0.4212,\n",
      "          0.8122, 0.4453, 0.6177, 0.9748, 0.8319, 0.3758, 0.8792, 0.1650,\n",
      "          0.0102, 0.3379, 0.8691, 0.8027],\n",
      "         [0.1842, 0.5502, 0.4974, 0.9734, 0.5785, 0.4079, 0.1618, 0.7604,\n",
      "          0.4117, 0.5118, 0.8078, 0.3513, 0.4774, 0.9038, 0.5474, 0.5170,\n",
      "          0.7738, 0.3194, 0.6362, 0.6893, 0.2184, 0.9816, 0.7887, 0.4984,\n",
      "          0.8705, 0.4278, 0.0890, 0.3098],\n",
      "         [0.8562, 0.6250, 0.8759, 0.9332, 0.7087, 0.3740, 0.1159, 0.5732,\n",
      "          0.0584, 0.4640, 0.3418, 0.7859, 0.6353, 0.8641, 0.4052, 0.1493,\n",
      "          0.2929, 0.9352, 0.1632, 0.8288, 0.6376, 0.6813, 0.4633, 0.8837,\n",
      "          0.2072, 0.3649, 0.1427, 0.9038],\n",
      "         [0.6668, 0.6770, 0.4064, 0.7690, 0.7619, 0.2286, 0.6475, 0.6114,\n",
      "          0.3316, 0.2434, 0.2449, 0.7603, 0.4265, 0.6622, 0.0630, 0.3129,\n",
      "          0.9861, 0.0375, 0.5839, 0.8896, 0.7767, 0.5943, 0.9452, 0.7924,\n",
      "          0.8106, 0.5029, 0.3747, 0.2147],\n",
      "         [0.1488, 0.4657, 0.6548, 0.3338, 0.4750, 0.2067, 0.9533, 0.7140,\n",
      "          0.4484, 0.5363, 0.8475, 0.7367, 0.1547, 0.0795, 0.1610, 0.3752,\n",
      "          0.4912, 0.2354, 0.2583, 0.7445, 0.2258, 0.6431, 0.7806, 0.3068,\n",
      "          0.1542, 0.9903, 0.3827, 0.6458],\n",
      "         [0.1499, 0.0163, 0.6453, 0.7670, 0.7817, 0.9285, 0.9271, 0.8727,\n",
      "          0.5974, 0.4269, 0.4845, 0.2860, 0.2057, 0.3950, 0.0051, 0.0688,\n",
      "          0.5947, 0.5471, 0.5583, 0.9563, 0.1547, 0.4426, 0.1316, 0.0527,\n",
      "          0.6919, 0.8824, 0.8374, 0.0490],\n",
      "         [0.0773, 0.4276, 0.7761, 0.7155, 0.1517, 0.7645, 0.6124, 0.8710,\n",
      "          0.0994, 0.2038, 0.9594, 0.7779, 0.8605, 0.2878, 0.7700, 0.8744,\n",
      "          0.5647, 0.1609, 0.3593, 0.5681, 0.0627, 0.6694, 0.4229, 0.9808,\n",
      "          0.8401, 0.1820, 0.4757, 0.6496],\n",
      "         [0.3527, 0.9114, 0.6897, 0.5226, 0.1441, 0.6897, 0.7389, 0.6859,\n",
      "          0.1386, 0.7115, 0.2943, 0.0416, 0.5579, 0.9255, 0.0822, 0.3507,\n",
      "          0.0466, 0.4914, 0.2174, 0.8376, 0.6197, 0.1200, 0.1106, 0.4286,\n",
      "          0.6678, 0.8989, 0.4637, 0.2862],\n",
      "         [0.1412, 0.8787, 0.1241, 0.1118, 0.2028, 0.7402, 0.3052, 0.1047,\n",
      "          0.3922, 0.2900, 0.2396, 0.9979, 0.8715, 0.8756, 0.7300, 0.9429,\n",
      "          0.1253, 0.9682, 0.0383, 0.4439, 0.3717, 0.9312, 0.9787, 0.4634,\n",
      "          0.1639, 0.1139, 0.0473, 0.9482],\n",
      "         [0.1747, 0.7073, 0.9363, 0.7846, 0.1403, 0.6646, 0.0671, 0.4998,\n",
      "          0.4134, 0.3785, 0.1815, 0.1702, 0.1983, 0.7897, 0.5832, 0.3036,\n",
      "          0.9703, 0.9454, 0.4370, 0.7254, 0.6279, 0.8772, 0.5118, 0.1699,\n",
      "          0.1760, 0.0722, 0.6013, 0.9415],\n",
      "         [0.6612, 0.0854, 0.8748, 0.1884, 0.3675, 0.7861, 0.1979, 0.0753,\n",
      "          0.7731, 0.6878, 0.6929, 0.0040, 0.8866, 0.8561, 0.2417, 0.8595,\n",
      "          0.3058, 0.2791, 0.2648, 0.8768, 0.9709, 0.6617, 0.5329, 0.6850,\n",
      "          0.0989, 0.7339, 0.3482, 0.5684],\n",
      "         [0.4079, 0.8155, 0.3929, 0.2076, 0.5411, 0.2704, 0.7914, 0.2031,\n",
      "          0.8043, 0.1277, 0.0798, 0.7547, 0.4288, 0.5099, 0.0404, 0.2790,\n",
      "          0.5161, 0.6412, 0.9480, 0.6721, 0.9934, 0.5729, 0.4568, 0.4049,\n",
      "          0.5865, 0.6430, 0.7997, 0.9936],\n",
      "         [0.4793, 0.2559, 0.2915, 0.6385, 0.0937, 0.4316, 0.7208, 0.4301,\n",
      "          0.0841, 0.7824, 0.4040, 0.2920, 0.3640, 0.9837, 0.8027, 0.8665,\n",
      "          0.1553, 0.1161, 0.9097, 0.6208, 0.0483, 0.2513, 0.4192, 0.7242,\n",
      "          0.8997, 0.0869, 0.1567, 0.6498],\n",
      "         [0.0385, 0.2074, 0.5499, 0.3205, 0.5535, 0.1241, 0.0709, 0.8793,\n",
      "          0.4732, 0.9994, 0.7424, 0.1500, 0.1003, 0.9756, 0.5964, 0.4109,\n",
      "          0.0213, 0.2326, 0.0192, 0.6897, 0.7470, 0.3333, 0.6621, 0.8856,\n",
      "          0.5912, 0.2499, 0.8738, 0.6886],\n",
      "         [0.8453, 0.1660, 0.5711, 0.0325, 0.8644, 0.5310, 0.0778, 0.1395,\n",
      "          0.4264, 0.7367, 0.9815, 0.8053, 0.7041, 0.4533, 0.2659, 0.3200,\n",
      "          0.2671, 0.0828, 0.0657, 0.0508, 0.3590, 0.4969, 0.4265, 0.1313,\n",
      "          0.3009, 0.1167, 0.7742, 0.1943],\n",
      "         [0.2202, 0.0148, 0.5429, 0.3082, 0.2626, 0.3309, 0.1433, 0.2027,\n",
      "          0.0163, 0.8789, 0.1635, 0.4694, 0.5197, 0.4443, 0.7360, 0.6806,\n",
      "          0.3755, 0.2442, 0.0106, 0.8983, 0.1466, 0.2201, 0.1210, 0.9722,\n",
      "          0.0966, 0.1837, 0.5123, 0.6459],\n",
      "         [0.2117, 0.0875, 0.0908, 0.3857, 0.7238, 0.4885, 0.6018, 0.8104,\n",
      "          0.6672, 0.6208, 0.6219, 0.0909, 0.7126, 0.3947, 0.9572, 0.8640,\n",
      "          0.8012, 0.7745, 0.8827, 0.8751, 0.5051, 0.6967, 0.6511, 0.3895,\n",
      "          0.0483, 0.0692, 0.6485, 0.0673],\n",
      "         [0.5796, 0.5245, 0.8057, 0.0578, 0.2745, 0.4604, 0.0560, 0.6163,\n",
      "          0.2501, 0.8610, 0.6979, 0.4726, 0.4116, 0.1190, 0.7383, 0.5135,\n",
      "          0.7756, 0.0415, 0.0503, 0.2672, 0.1174, 0.3116, 0.9325, 0.3039,\n",
      "          0.3024, 0.0435, 0.7893, 0.6701],\n",
      "         [0.7409, 0.4630, 0.9471, 0.2756, 0.6278, 0.3727, 0.8298, 0.8946,\n",
      "          0.3886, 0.6891, 0.6739, 0.4438, 0.2886, 0.3569, 0.3224, 0.4705,\n",
      "          0.4082, 0.8126, 0.3883, 0.2968, 0.0816, 0.4400, 0.1198, 0.0752,\n",
      "          0.7455, 0.6904, 0.8707, 0.0011],\n",
      "         [0.7422, 0.3624, 0.1258, 0.9387, 0.3436, 0.1204, 0.3056, 0.4365,\n",
      "          0.5684, 0.8147, 0.4806, 0.8000, 0.1890, 0.6770, 0.5647, 0.2104,\n",
      "          0.3933, 0.1137, 0.6642, 0.7297, 0.5367, 0.2461, 0.4347, 0.9554,\n",
      "          0.9840, 0.5175, 0.9706, 0.0939],\n",
      "         [0.9036, 0.8305, 0.7703, 0.7488, 0.7166, 0.2365, 0.2478, 0.2698,\n",
      "          0.0073, 0.6993, 0.5974, 0.1596, 0.8764, 0.8956, 0.3380, 0.6410,\n",
      "          0.0027, 0.2951, 0.5178, 0.7408, 0.6303, 0.6211, 0.6748, 0.6312,\n",
      "          0.2643, 0.9137, 0.3201, 0.4834],\n",
      "         [0.3570, 0.0658, 0.6229, 0.5940, 0.5340, 0.2596, 0.1454, 0.5164,\n",
      "          0.4142, 0.4949, 0.1427, 0.1847, 0.0357, 0.5126, 0.8356, 0.7001,\n",
      "          0.1653, 0.6982, 0.8418, 0.0454, 0.6705, 0.0232, 0.2972, 0.5646,\n",
      "          0.9196, 0.7924, 0.9993, 0.4922],\n",
      "         [0.8901, 0.9221, 0.6197, 0.9968, 0.3698, 0.1248, 0.9487, 0.3403,\n",
      "          0.0492, 0.8591, 0.5826, 0.6527, 0.2335, 0.2841, 0.7059, 0.2113,\n",
      "          0.3371, 0.9599, 0.3564, 0.6808, 0.7250, 0.7641, 0.6605, 0.7690,\n",
      "          0.1256, 0.2351, 0.5301, 0.0767],\n",
      "         [0.6023, 0.1964, 0.0084, 0.6471, 0.6997, 0.8234, 0.1662, 0.1771,\n",
      "          0.4758, 0.7771, 0.9880, 0.6092, 0.0840, 0.3303, 0.3112, 0.0571,\n",
      "          0.8432, 0.4921, 0.5013, 0.8022, 0.4906, 0.0348, 0.2875, 0.6686,\n",
      "          0.6391, 0.5549, 0.1308, 0.9461],\n",
      "         [0.2288, 0.8714, 0.9927, 0.4350, 0.8409, 0.5575, 0.2969, 0.8448,\n",
      "          0.2276, 0.9450, 0.8495, 0.1070, 0.2754, 0.1575, 0.5371, 0.1864,\n",
      "          0.9071, 0.6782, 0.2841, 0.4344, 0.9120, 0.3424, 0.3865, 0.3499,\n",
      "          0.0938, 0.7340, 0.8116, 0.9264],\n",
      "         [0.1238, 0.3716, 0.8997, 0.1958, 0.9477, 0.3338, 0.6533, 0.3363,\n",
      "          0.3156, 0.5218, 0.0995, 0.1165, 0.6935, 0.4100, 0.9959, 0.9796,\n",
      "          0.0448, 0.5370, 0.6835, 0.2557, 0.6158, 0.4707, 0.7014, 0.2805,\n",
      "          0.8999, 0.4386, 0.2062, 0.8048],\n",
      "         [0.4527, 0.8091, 0.9656, 0.5076, 0.8265, 0.8690, 0.1595, 0.4516,\n",
      "          0.0112, 0.5862, 0.2794, 0.9022, 0.8123, 0.9007, 0.7236, 0.1175,\n",
      "          0.0157, 0.8441, 0.6980, 0.3403, 0.1919, 0.5676, 0.8159, 0.7021,\n",
      "          0.9885, 0.4074, 0.7374, 0.0906]]])\n"
     ]
    }
   ],
   "source": [
    "# 모델에 입력을 전달하여 호출하면 2차원 텐서 반환\n",
    "# 2차원 텐서의 dim=0은 각 분류에 대한 원시 예측값 10개\n",
    "# dim=1은 각 출력의 개별값 해당\n",
    "# 원시 예측값을 softmax에 통과시켜 예측 확률 출력\n",
    "\n",
    "X = torch.rand(1, 28, 28, device=device)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c253f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0371,  0.0339, -0.0115,  0.0308, -0.0097, -0.0295, -0.1475,  0.0335,\n",
       "         -0.0267, -0.0118]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = model(X)\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29047381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0979, 0.1052, 0.1005, 0.1048, 0.1007, 0.0987, 0.0877, 0.1051, 0.0990,\n",
       "         0.1005]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_prob = nn.Softmax(dim=1)(logits)\n",
    "pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9476ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = pred_prob.argmax(1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df88e332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# 모델 계층\n",
    "input_image = torch.rand(3,28,28)\n",
    "print(input_image.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f922285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 784])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flatten: 계층을 초기화\n",
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "flat_image.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42f02599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "# Linear: 입력에 선형 변환을 하는 모듈\n",
    "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
    "hidden = layer1(flat_image)\n",
    "print(hidden.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c503ac34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before ReLU: tensor([[ 0.3904, -0.3995,  0.1298, -0.0443,  0.2154, -0.0148,  0.5177,  0.0840,\n",
      "          0.3237,  0.2277,  0.2891,  0.3337,  0.4667, -0.3059, -0.0841, -0.1507,\n",
      "         -0.1646, -0.4649, -0.0550,  0.2472],\n",
      "        [ 0.4401, -0.3873,  0.1790, -0.0102, -0.2157, -0.0160,  0.6138,  0.4156,\n",
      "         -0.1637, -0.0777,  0.1759,  0.1571,  0.7720, -0.0644,  0.3048,  0.0576,\n",
      "          0.0585, -0.4929, -0.0169,  0.0225],\n",
      "        [ 0.6731, -0.4043,  0.3577, -0.0426, -0.0746, -0.4360,  0.7407,  0.4777,\n",
      "          0.0860,  0.2381,  0.5404,  0.0934,  0.5369, -0.1995,  0.0267, -0.2037,\n",
      "         -0.0049, -0.8784,  0.0223,  0.1268]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "After ReLU: tensor([[0.3904, 0.0000, 0.1298, 0.0000, 0.2154, 0.0000, 0.5177, 0.0840, 0.3237,\n",
      "         0.2277, 0.2891, 0.3337, 0.4667, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.2472],\n",
      "        [0.4401, 0.0000, 0.1790, 0.0000, 0.0000, 0.0000, 0.6138, 0.4156, 0.0000,\n",
      "         0.0000, 0.1759, 0.1571, 0.7720, 0.0000, 0.3048, 0.0576, 0.0585, 0.0000,\n",
      "         0.0000, 0.0225],\n",
      "        [0.6731, 0.0000, 0.3577, 0.0000, 0.0000, 0.0000, 0.7407, 0.4777, 0.0860,\n",
      "         0.2381, 0.5404, 0.0934, 0.5369, 0.0000, 0.0267, 0.0000, 0.0000, 0.0000,\n",
      "         0.0223, 0.1268]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# ReLU: 비선형 활성화는 모델의 입력과 출력 사이에 복잡한 관계를 만듦\n",
    "print(f\"Before ReLU: {hidden}\\n\\n\")\n",
    "hidden1 = nn.ReLU()(hidden)\n",
    "print(f\"After ReLU: {hidden1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe65b030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0739,  0.0782, -0.1272,  0.1587,  0.3976, -0.1183, -0.3197, -0.3298,\n",
       "          0.3677, -0.3085],\n",
       "        [ 0.0214,  0.1554, -0.1279,  0.1149,  0.1592, -0.1237, -0.1670, -0.1997,\n",
       "          0.3138, -0.2153],\n",
       "        [-0.0981,  0.1180, -0.1271,  0.1483,  0.1351, -0.1033, -0.2552, -0.1174,\n",
       "          0.2493, -0.3247]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sequential 순서를 갖는 모듈\n",
    "# 순차 컨테이너를 사용해 빠르게 신경망 생성 가능\n",
    "seq_modules = nn.Sequential(\n",
    "    flatten,\n",
    "    layer1,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 10)\n",
    ")\n",
    "\n",
    "input_image = torch.rand(3,28,28)\n",
    "logits = seq_modules(input_image)\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8a031e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0923, 0.1074, 0.0875, 0.1165, 0.1479, 0.0883, 0.0722, 0.0714, 0.1435,\n",
       "         0.0730],\n",
       "        [0.1013, 0.1158, 0.0872, 0.1112, 0.1162, 0.0876, 0.0839, 0.0812, 0.1357,\n",
       "         0.0799],\n",
       "        [0.0926, 0.1150, 0.0900, 0.1185, 0.1169, 0.0921, 0.0792, 0.0908, 0.1311,\n",
       "         0.0738]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Softmax: 신경망의 마지막 선형계층은 Softmax에 전달될 logits 반환\n",
    "# logits는 모델의 각 분류에 대한 예측 확률을 나타내도록 0 ~ 1 범위로 조정됨\n",
    "# dim: 값의 합이 1이 되는 차원\n",
    "softmax = nn.Softmax(dim=1)\n",
    "pred_prob = softmax(logits)\n",
    "pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "124dba75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure: NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[-0.0292,  0.0224,  0.0095,  ..., -0.0273, -0.0345, -0.0303],\n",
      "        [-0.0032,  0.0107,  0.0085,  ...,  0.0322,  0.0287,  0.0008]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([-0.0337,  0.0136], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[ 0.0232,  0.0381, -0.0358,  ...,  0.0164, -0.0265,  0.0047],\n",
      "        [ 0.0278, -0.0076, -0.0075,  ..., -0.0425,  0.0334, -0.0040]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([-0.0259, -0.0056], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[ 0.0236, -0.0323, -0.0308,  ..., -0.0390, -0.0334, -0.0401],\n",
      "        [-0.0307,  0.0359, -0.0375,  ...,  0.0150,  0.0140,  0.0396]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([-0.0300,  0.0203], grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 신경망 내의 많은 계층들을 매개변수화 됨\n",
    "# nn.Module을 상속함으로써 모델 객체 내의 모든 필드들이 자동으로 추척되며,\n",
    "# 모델의 모든 매개변수에 접근할 수 있게 됨\n",
    "print(f\"Model structure: {model}\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6aa226",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
